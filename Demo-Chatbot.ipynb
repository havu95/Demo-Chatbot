{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55985e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\havu1\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - wordcloud\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.3               |   py37h03978a9_2         3.1 MB  conda-forge\n",
      "    msgpack-python-1.0.2       |   py37h8c56517_1          80 KB  conda-forge\n",
      "    openssl-1.1.1l             |       h8ffe710_0         5.7 MB  conda-forge\n",
      "    wordcloud-1.8.1            |   py37hcc03f2d_1         194 KB  conda-forge\n",
      "    wrapt-1.12.1               |   py37hcc03f2d_3          46 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  msgpack-python     conda-forge/win-64::msgpack-python-1.0.2-py37h8c56517_1\n",
      "  wordcloud          conda-forge/win-64::wordcloud-1.8.1-py37hcc03f2d_1\n",
      "  wrapt              conda-forge/win-64::wrapt-1.12.1-py37hcc03f2d_3\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-4.10.3-py37haa95532_0 --> conda-forge::conda-4.10.3-py37h03978a9_2\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-h5b45459_0\n",
      "  certifi            pkgs/main::certifi-2021.5.30-py37haa9~ --> conda-forge::certifi-2021.5.30-py37h03978a9_0\n",
      "  openssl              pkgs/main::openssl-1.1.1l-h2bbff1b_0 --> conda-forge::openssl-1.1.1l-h8ffe710_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "wordcloud-1.8.1      | 194 KB    |            |   0% \n",
      "wordcloud-1.8.1      | 194 KB    | 8          |   8% \n",
      "wordcloud-1.8.1      | 194 KB    | ########## | 100% \n",
      "wordcloud-1.8.1      | 194 KB    | ########## | 100% \n",
      "\n",
      "wrapt-1.12.1         | 46 KB     |            |   0% \n",
      "wrapt-1.12.1         | 46 KB     | ########## | 100% \n",
      "\n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    | 8          |   8% \n",
      "openssl-1.1.1l       | 5.7 MB    | ##9        |  29% \n",
      "openssl-1.1.1l       | 5.7 MB    | #####2     |  52% \n",
      "openssl-1.1.1l       | 5.7 MB    | #######4   |  74% \n",
      "openssl-1.1.1l       | 5.7 MB    | #########7 |  97% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########## | 100% \n",
      "\n",
      "msgpack-python-1.0.2 | 80 KB     |            |   0% \n",
      "msgpack-python-1.0.2 | 80 KB     | ########## | 100% \n",
      "msgpack-python-1.0.2 | 80 KB     | ########## | 100% \n",
      "\n",
      "conda-4.10.3         | 3.1 MB    |            |   0% \n",
      "conda-4.10.3         | 3.1 MB    | ##1        |  21% \n",
      "conda-4.10.3         | 3.1 MB    | ######3    |  64% \n",
      "conda-4.10.3         | 3.1 MB    | ########## | 100% \n",
      "conda-4.10.3         | 3.1 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda==custom=py37_1\n",
      "  - defaults/win-64::astroid==2.6.2=py37haa95532_0\n",
      "  - defaults/noarch::dask==2021.7.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::distributed==2021.7.0=py37haa95532_0\n",
      "  - defaults/win-64::keras==2.2.4=0\n",
      "  - defaults/win-64::pylint==2.9.3=py37haa95532_1\n",
      "  - defaults/noarch::pyls-black==0.4.6=hd3eb1b0_0\n",
      "  - defaults/noarch::pyls-spyder==0.3.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::python-language-server==0.36.2=pyhd3eb1b0_0\n",
      "  - defaults/win-64::spyder==3.3.6=py37_0\n",
      "  - defaults/win-64::tensorflow==1.14.0=gpu_py37h5512b17_0\n",
      "  - defaults/win-64::tensorflow-base==1.14.0=gpu_py37h55fc52a_0\n",
      "  - defaults/noarch::tensorflow-estimator==1.14.0=py_0\n",
      "  - defaults/win-64::tensorflow-gpu==1.14.0=h0d30ee6_0\n",
      "  - defaults/noarch::tensorflow-probability==0.7=py_2\n",
      "  - defaults/win-64::_anaconda_depends==2020.07=py37_0\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1099b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\havu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\havu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\havu1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc01ed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>a couple of years ago my friends was going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Roommate when he was going through death and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flagged</td>\n",
       "      <td>i've had a couple of friends (you could say mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Listened to someone talk about relationship tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I will always listen. I comforted my sister wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                      response_text\n",
       "0  not_flagged              I try and avoid this sort of conflict\n",
       "1      flagged  Had a friend open up to me about his mental ad...\n",
       "2      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  not_flagged  Only really one friend who doesn't fit into th...\n",
       "5  not_flagged  a couple of years ago my friends was going to ...\n",
       "6      flagged  Roommate when he was going through death and l...\n",
       "7      flagged  i've had a couple of friends (you could say mo...\n",
       "8  not_flagged  Listened to someone talk about relationship tr...\n",
       "9      flagged  I will always listen. I comforted my sister wh..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"./Downloads/Sheet_1.csv\",encoding= \"latin1\" )\n",
    "data.drop([\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\n",
    "           \"Unnamed: 6\",\"Unnamed: 7\",], axis = 1, inplace =True)\n",
    "data = pd.concat([data[\"class\"],data[\"response_text\"]], axis = 1)\n",
    "\n",
    "data.dropna(axis=0, inplace =True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef188020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                      response_text\n",
       "0      0              I try and avoid this sort of conflict\n",
       "1      1  Had a friend open up to me about his mental ad...\n",
       "2      1  I saved a girl from suicide once. She was goin...\n",
       "3      0  i cant think of one really...i think i may hav...\n",
       "4      0  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"class\"] = [1 if each == \"flagged\" else 0 for each in data[\"class\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67f2ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have helped advise friends who have faced circumstances similar to mine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.response_text[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a69a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have helped advise friends who have faced circumstances similar to mine\n"
     ]
    }
   ],
   "source": [
    "first_text = data.response_text[16]\n",
    "text = re.sub(\"[^a-zA-Z]\",\" \",first_text)\n",
    "text = text.lower() \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f14e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['helped', 'advise', 'friends', 'faced', 'circumstances', 'similar', 'mine']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(text)\n",
    "text = [ word for word in text if not word in set(stopwords.words(\"english\"))]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1cc5d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help', 'advise', 'friend', 'face', 'circumstance', 'similar', 'mine']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "text = [(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word, \"n\"),pos = \"v\"),pos=\"a\")) for word in text]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfcafb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in data.response_text:\n",
    "       \n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower() \n",
    "    \n",
    "    description = nltk.word_tokenize(description)\n",
    "    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    description = (lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(word, \"n\"),pos = \"v\"),pos=\"a\") for word in description)\n",
    "    \n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f99493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help advise friend face circumstance similar mine'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf8011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Most Used Words: ['addiction', 'advice', 'alone', 'always', 'anxiety', 'anything', 'back', 'best', 'bring', 'call', 'care', 'come', 'comfort', 'could', 'deal', 'depression', 'describe', 'dont', 'end', 'even', 'everything', 'experience', 'face', 'feel', 'find', 'friend', 'get', 'gf', 'girl', 'girlfriend', 'give', 'go', 'good', 'grade', 'happen', 'help', 'helpful', 'issue', 'kid', 'kill', 'know', 'last', 'let', 'life', 'like', 'listen', 'little', 'look', 'lot', 'make', 'many', 'may', 'much', 'need', 'never', 'night', 'offer', 'often', 'one', 'open', 'others', 'people', 'person', 'personal', 'pretty', 'problem', 'really', 'relationship', 'say', 'school', 'see', 'self', 'severe', 'share', 'shit', 'similar', 'simply', 'situation', 'someone', 'sometimes', 'start', 'struggle', 'stuff', 'suicide', 'support', 'talk', 'tell', 'think', 'though', 'time', 'trouble', 'try', 'use', 'want', 'way', 'week', 'well', 'work', 'would', 'year']\n"
     ]
    }
   ],
   "source": [
    "max_features = 100\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Top {} Most Used Words: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e985a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720c8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdf592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
